{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tensorflow.keras.layers import TextVectorization\nimport re,string\nfrom tensorflow.keras.layers import LSTM,Dense,Embedding,Dropout,LayerNormalization","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-10T14:39:11.984376Z","iopub.execute_input":"2023-04-10T14:39:11.985569Z","iopub.status.idle":"2023-04-10T14:39:11.992125Z","shell.execute_reply.started":"2023-04-10T14:39:11.985511Z","shell.execute_reply":"2023-04-10T14:39:11.99082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/simple-dialogs-for-chatbot/dialogs.txt',sep='\\t',names=['question','answer'])\nprint(f'Dataframe size: {len(df)}')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-10T14:39:12.052382Z","iopub.execute_input":"2023-04-10T14:39:12.052685Z","iopub.status.idle":"2023-04-10T14:39:12.080923Z","shell.execute_reply.started":"2023-04-10T14:39:12.052655Z","shell.execute_reply":"2023-04-10T14:39:12.079788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"## Data Visualization","metadata":{}},{"cell_type":"code","source":"\n\ndf['question tokens']=df['question'].apply(lambda x:len(x.split()))\ndf['answer tokens']=df['answer'].apply(lambda x:len(x.split()))\nplt.style.use('fivethirtyeight')\nfig,ax=plt.subplots(nrows=1,ncols=2,figsize=(20,5))\nsns.set_palette('Set2')\nsns.histplot(x=df['question tokens'],data=df,kde=True,ax=ax[0])\nsns.histplot(x=df['answer tokens'],data=df,kde=True,ax=ax[1])\nsns.jointplot(x='question tokens',y='answer tokens',data=df,kind='kde',fill=True,cmap='YlGnBu')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-10T14:39:12.082617Z","iopub.execute_input":"2023-04-10T14:39:12.083433Z","iopub.status.idle":"2023-04-10T14:39:14.963476Z","shell.execute_reply.started":"2023-04-10T14:39:12.083395Z","shell.execute_reply":"2023-04-10T14:39:14.9624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Text Cleaning","metadata":{}},{"cell_type":"code","source":"\n\ndef clean_text(text):\n    text=re.sub('-',' ',text.lower())\n    text=re.sub('[.]',' . ',text)\n    text=re.sub('[1]',' 1 ',text)\n    text=re.sub('[2]',' 2 ',text)\n    text=re.sub('[3]',' 3 ',text)\n    text=re.sub('[4]',' 4 ',text)\n    text=re.sub('[5]',' 5 ',text)\n    text=re.sub('[6]',' 6 ',text)\n    text=re.sub('[7]',' 7 ',text)\n    text=re.sub('[8]',' 8 ',text)\n    text=re.sub('[9]',' 9 ',text)\n    text=re.sub('[0]',' 0 ',text)\n    text=re.sub('[,]',' , ',text)\n    text=re.sub('[?]',' ? ',text)\n    text=re.sub('[!]',' ! ',text)\n    text=re.sub('[$]',' $ ',text)\n    text=re.sub('[&]',' & ',text)\n    text=re.sub('[/]',' / ',text)\n    text=re.sub('[:]',' : ',text)\n    text=re.sub('[;]',' ; ',text)\n    text=re.sub('[*]',' * ',text)\n    text=re.sub('[\\']',' \\' ',text)\n    text=re.sub('[\\\"]',' \\\" ',text)\n    text=re.sub('\\t',' ',text)\n    return text\n\ndf.drop(columns=['answer tokens','question tokens'],axis=1,inplace=True)\ndf['encoder_inputs']=df['question'].apply(clean_text)\ndf['decoder_targets']=df['answer'].apply(clean_text)+' <end>'\ndf['decoder_inputs']='<start> '+df['answer'].apply(clean_text)+' <end>'\n\ndf.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T14:39:14.965636Z","iopub.execute_input":"2023-04-10T14:39:14.966306Z","iopub.status.idle":"2023-04-10T14:39:15.252707Z","shell.execute_reply.started":"2023-04-10T14:39:14.966264Z","shell.execute_reply":"2023-04-10T14:39:15.251669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['encoder input tokens']=df['encoder_inputs'].apply(lambda x:len(x.split()))\ndf['decoder input tokens']=df['decoder_inputs'].apply(lambda x:len(x.split()))\ndf['decoder target tokens']=df['decoder_targets'].apply(lambda x:len(x.split()))\nplt.style.use('fivethirtyeight')\nfig,ax=plt.subplots(nrows=1,ncols=3,figsize=(20,5))\nsns.set_palette('Set2')\nsns.histplot(x=df['encoder input tokens'],data=df,kde=True,ax=ax[0])\nsns.histplot(x=df['decoder input tokens'],data=df,kde=True,ax=ax[1])\nsns.histplot(x=df['decoder target tokens'],data=df,kde=True,ax=ax[2])\nsns.jointplot(x='encoder input tokens',y='decoder target tokens',data=df,kind='kde',fill=True,cmap='YlGnBu')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-10T14:39:15.254268Z","iopub.execute_input":"2023-04-10T14:39:15.255077Z","iopub.status.idle":"2023-04-10T14:39:18.217577Z","shell.execute_reply.started":"2023-04-10T14:39:15.255037Z","shell.execute_reply":"2023-04-10T14:39:18.216544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"After preprocessing: {' '.join(df[df['encoder input tokens'].max()==df['encoder input tokens']]['encoder_inputs'].values.tolist())}\")\nprint(f\"Max encoder input length: {df['encoder input tokens'].max()}\")\nprint(f\"Max decoder input length: {df['decoder input tokens'].max()}\")\nprint(f\"Max decoder target length: {df['decoder target tokens'].max()}\")\n\ndf.drop(columns=['question','answer','encoder input tokens','decoder input tokens','decoder target tokens'],axis=1,inplace=True)\nparams={\n    \"vocab_size\":2500,\n    \"max_sequence_length\":30,\n    \"learning_rate\":0.008,\n    \"batch_size\":149,\n    \"lstm_cells\":256,\n    \"embedding_dim\":256,\n    \"buffer_size\":10000\n}\nlearning_rate=params['learning_rate']\nbatch_size=params['batch_size']\nembedding_dim=params['embedding_dim']\nlstm_cells=params['lstm_cells']\nvocab_size=params['vocab_size']\nbuffer_size=params['buffer_size']\nmax_sequence_length=params['max_sequence_length']\ndf.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T14:39:18.220471Z","iopub.execute_input":"2023-04-10T14:39:18.221137Z","iopub.status.idle":"2023-04-10T14:39:18.242904Z","shell.execute_reply.started":"2023-04-10T14:39:18.221095Z","shell.execute_reply":"2023-04-10T14:39:18.241823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tokenization","metadata":{}},{"cell_type":"code","source":"\n\nvectorize_layer=TextVectorization(\n    max_tokens=vocab_size,\n    standardize=None,\n    output_mode='int',\n    output_sequence_length=max_sequence_length\n)\nvectorize_layer.adapt(df['encoder_inputs']+' '+df['decoder_targets']+' <start> <end>')\nvocab_size=len(vectorize_layer.get_vocabulary())\nprint(f'Vocab size: {len(vectorize_layer.get_vocabulary())}')\nprint(f'{vectorize_layer.get_vocabulary()[:12]}')","metadata":{"execution":{"iopub.status.busy":"2023-04-10T14:39:18.244303Z","iopub.execute_input":"2023-04-10T14:39:18.244875Z","iopub.status.idle":"2023-04-10T14:39:18.667034Z","shell.execute_reply.started":"2023-04-10T14:39:18.244836Z","shell.execute_reply":"2023-04-10T14:39:18.665847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sequences2ids(sequence):\n    return vectorize_layer(sequence)\n\ndef ids2sequences(ids):\n    decode=''\n    if type(ids)==int:\n        ids=[ids]\n    for id in ids:\n        decode+=vectorize_layer.get_vocabulary()[id]+' '\n    return decode\n\nx=sequences2ids(df['encoder_inputs'])\nyd=sequences2ids(df['decoder_inputs'])\ny=sequences2ids(df['decoder_targets'])\n\nprint(f'Question sentence: hi , how are you ?')\nprint(f'Question to tokens: {sequences2ids(\"hi , how are you ?\")[:10]}')\nprint(f'Encoder input shape: {x.shape}')\nprint(f'Decoder input shape: {yd.shape}')\nprint(f'Decoder target shape: {y.shape}')","metadata":{"execution":{"iopub.status.busy":"2023-04-10T14:39:18.668721Z","iopub.execute_input":"2023-04-10T14:39:18.669135Z","iopub.status.idle":"2023-04-10T14:39:18.730498Z","shell.execute_reply.started":"2023-04-10T14:39:18.669096Z","shell.execute_reply":"2023-04-10T14:39:18.729432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Encoder input: {x[0][:12]} ...')\nprint(f'Decoder input: {yd[0][:12]} ...')    # shifted by one time step of the target as input to decoder is the output of the previous timestep\nprint(f'Decoder target: {y[0][:12]} ...')","metadata":{"execution":{"iopub.status.busy":"2023-04-10T14:39:18.732032Z","iopub.execute_input":"2023-04-10T14:39:18.732371Z","iopub.status.idle":"2023-04-10T14:39:18.744208Z","shell.execute_reply.started":"2023-04-10T14:39:18.732336Z","shell.execute_reply":"2023-04-10T14:39:18.742959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=tf.data.Dataset.from_tensor_slices((x,yd,y))\ndata=data.shuffle(buffer_size)\n\ntrain_data=data.take(int(.9*len(data)))\ntrain_data=train_data.cache()\ntrain_data=train_data.shuffle(buffer_size)\ntrain_data=train_data.batch(batch_size)\ntrain_data=train_data.prefetch(tf.data.AUTOTUNE)\ntrain_data_iterator=train_data.as_numpy_iterator()\n\nval_data=data.skip(int(.9*len(data))).take(int(.1*len(data)))\nval_data=val_data.batch(batch_size)\nval_data=val_data.prefetch(tf.data.AUTOTUNE)\n\n_=train_data_iterator.next()\nprint(f'Number of train batches: {len(train_data)}')\nprint(f'Number of training data: {len(train_data)*batch_size}')\nprint(f'Number of validation batches: {len(val_data)}')\nprint(f'Number of validation data: {len(val_data)*batch_size}')\nprint(f'Encoder Input shape (with batches): {_[0].shape}')\nprint(f'Decoder Input shape (with batches): {_[1].shape}')\nprint(f'Target Output shape (with batches): {_[2].shape}')","metadata":{"execution":{"iopub.status.busy":"2023-04-10T14:39:18.746798Z","iopub.execute_input":"2023-04-10T14:39:18.747514Z","iopub.status.idle":"2023-04-10T14:39:18.792975Z","shell.execute_reply.started":"2023-04-10T14:39:18.747469Z","shell.execute_reply":"2023-04-10T14:39:18.79152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build Models","metadata":{}},{"cell_type":"markdown","source":"## Build Encoder","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Encoder(tf.keras.models.Model):\n    def __init__(self,units,embedding_dim,vocab_size,*args,**kwargs) -> None:\n        super().__init__(*args,**kwargs)\n        self.units=units\n        self.vocab_size=vocab_size\n        self.embedding_dim=embedding_dim\n        self.embedding=Embedding(\n            vocab_size,\n            embedding_dim,\n            name='encoder_embedding',\n            mask_zero=True,\n            embeddings_initializer=tf.keras.initializers.GlorotNormal()\n        )\n        self.normalize=LayerNormalization()\n        self.lstm=LSTM(\n            units,\n            dropout=.4,\n            return_state=True,\n            return_sequences=True,\n            name='encoder_lstm',\n            kernel_initializer=tf.keras.initializers.GlorotNormal()\n        )\n    \n    def call(self,encoder_inputs):\n        self.inputs=encoder_inputs\n        x=self.embedding(encoder_inputs)\n        x=self.normalize(x)\n        x=Dropout(.4)(x)\n        encoder_outputs,encoder_state_h,encoder_state_c=self.lstm(x)\n        self.outputs=[encoder_state_h,encoder_state_c]\n        return encoder_state_h,encoder_state_c\n\nencoder=Encoder(lstm_cells,embedding_dim,vocab_size,name='encoder')\nencoder.call(_[0])","metadata":{"execution":{"iopub.status.busy":"2023-04-10T14:39:18.794286Z","iopub.execute_input":"2023-04-10T14:39:18.794606Z","iopub.status.idle":"2023-04-10T14:39:18.867692Z","shell.execute_reply.started":"2023-04-10T14:39:18.794571Z","shell.execute_reply":"2023-04-10T14:39:18.866734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Build Encoder##  Build Decoder","metadata":{}},{"cell_type":"code","source":"class Decoder(tf.keras.models.Model):\n    def __init__(self,units,embedding_dim,vocab_size,*args,**kwargs) -> None:\n        super().__init__(*args,**kwargs)\n        self.units=units\n        self.embedding_dim=embedding_dim\n        self.vocab_size=vocab_size\n        self.embedding=Embedding(\n            vocab_size,\n            embedding_dim,\n            name='decoder_embedding',\n            mask_zero=True,\n            embeddings_initializer=tf.keras.initializers.HeNormal()\n        )\n        self.normalize=LayerNormalization()\n        self.lstm=LSTM(\n            units,\n            dropout=.4,\n            return_state=True,\n            return_sequences=True,\n            name='decoder_lstm',\n            kernel_initializer=tf.keras.initializers.HeNormal()\n        )\n        self.fc=Dense(\n            vocab_size,\n            activation='softmax',\n            name='decoder_dense',\n            kernel_initializer=tf.keras.initializers.HeNormal()\n        )\n    \n    def call(self,decoder_inputs,encoder_states):\n        x=self.embedding(decoder_inputs)\n        x=self.normalize(x)\n        x=Dropout(.4)(x)\n        x,decoder_state_h,decoder_state_c=self.lstm(x,initial_state=encoder_states)\n        x=self.normalize(x)\n        x=Dropout(.4)(x)\n        return self.fc(x)\n\ndecoder=Decoder(lstm_cells,embedding_dim,vocab_size,name='decoder')\ndecoder(_[1][:1],encoder(_[0][:1]))","metadata":{"execution":{"iopub.status.busy":"2023-04-10T14:39:18.872231Z","iopub.execute_input":"2023-04-10T14:39:18.872561Z","iopub.status.idle":"2023-04-10T14:39:18.966946Z","shell.execute_reply.started":"2023-04-10T14:39:18.872529Z","shell.execute_reply":"2023-04-10T14:39:18.965715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build Training Model","metadata":{}},{"cell_type":"code","source":"class ChatBotTrainer(tf.keras.models.Model):\n    def __init__(self,encoder,decoder,*args,**kwargs):\n        super().__init__(*args,**kwargs)\n        self.encoder=encoder\n        self.decoder=decoder\n\n    def loss_fn(self,y_true,y_pred):\n        loss=self.loss(y_true,y_pred)\n        mask=tf.math.logical_not(tf.math.equal(y_true,0))\n        mask=tf.cast(mask,dtype=loss.dtype)\n        loss*=mask\n        return tf.reduce_mean(loss)\n    \n    def accuracy_fn(self,y_true,y_pred):\n        pred_values = tf.cast(tf.argmax(y_pred, axis=-1), dtype='int64')\n        correct = tf.cast(tf.equal(y_true, pred_values), dtype='float64')\n        mask = tf.cast(tf.greater(y_true, 0), dtype='float64')\n        n_correct = tf.keras.backend.sum(mask * correct)\n        n_total = tf.keras.backend.sum(mask)\n        return n_correct / n_total\n\n    def call(self,inputs):\n        encoder_inputs,decoder_inputs=inputs\n        encoder_states=self.encoder(encoder_inputs)\n        return self.decoder(decoder_inputs,encoder_states)\n\n    def train_step(self,batch):\n        encoder_inputs,decoder_inputs,y=batch\n        with tf.GradientTape() as tape:\n            encoder_states=self.encoder(encoder_inputs,training=True)\n            y_pred=self.decoder(decoder_inputs,encoder_states,training=True)\n            loss=self.loss_fn(y,y_pred)\n            acc=self.accuracy_fn(y,y_pred)\n\n        variables=self.encoder.trainable_variables+self.decoder.trainable_variables\n        grads=tape.gradient(loss,variables)\n        self.optimizer.apply_gradients(zip(grads,variables))\n        metrics={'loss':loss,'accuracy':acc}\n        return metrics\n    \n    def test_step(self,batch):\n        encoder_inputs,decoder_inputs,y=batch\n        encoder_states=self.encoder(encoder_inputs,training=True)\n        y_pred=self.decoder(decoder_inputs,encoder_states,training=True)\n        loss=self.loss_fn(y,y_pred)\n        acc=self.accuracy_fn(y,y_pred)\n        metrics={'loss':loss,'accuracy':acc}\n        return metrics","metadata":{"execution":{"iopub.status.busy":"2023-04-10T14:39:18.968296Z","iopub.execute_input":"2023-04-10T14:39:18.968623Z","iopub.status.idle":"2023-04-10T14:39:18.985101Z","shell.execute_reply.started":"2023-04-10T14:39:18.968587Z","shell.execute_reply":"2023-04-10T14:39:18.98391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=ChatBotTrainer(encoder,decoder,name='chatbot_trainer')\nmodel.compile(\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n    weighted_metrics=['loss','accuracy']\n)\nmodel(_[:2])","metadata":{"execution":{"iopub.status.busy":"2023-04-10T14:39:18.988521Z","iopub.execute_input":"2023-04-10T14:39:18.988828Z","iopub.status.idle":"2023-04-10T14:39:19.099854Z","shell.execute_reply.started":"2023-04-10T14:39:18.988798Z","shell.execute_reply":"2023-04-10T14:39:19.098812Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  Train Model","metadata":{}},{"cell_type":"code","source":"history=model.fit(\n    train_data,\n    epochs=100,\n    validation_data=val_data,\n    callbacks=[\n        tf.keras.callbacks.TensorBoard(log_dir='logs'),\n        tf.keras.callbacks.ModelCheckpoint('ckpt',verbose=1,save_best_only=True)\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T14:39:19.101117Z","iopub.execute_input":"2023-04-10T14:39:19.101473Z","iopub.status.idle":"2023-04-10T14:51:24.143596Z","shell.execute_reply.started":"2023-04-10T14:39:19.101424Z","shell.execute_reply":"2023-04-10T14:51:24.142418Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  Visualize Metrics","metadata":{}},{"cell_type":"code","source":"fig,ax=plt.subplots(nrows=1,ncols=2,figsize=(20,5))\nax[0].plot(history.history['loss'],label='loss',c='red')\nax[0].plot(history.history['val_loss'],label='val_loss',c = 'blue')\nax[0].set_xlabel('Epochs')\nax[1].set_xlabel('Epochs')\nax[0].set_ylabel('Loss')\nax[1].set_ylabel('Accuracy')\nax[0].set_title('Loss Metrics')\nax[1].set_title('Accuracy Metrics')\nax[1].plot(history.history['accuracy'],label='accuracy')\nax[1].plot(history.history['val_accuracy'],label='val_accuracy')\nax[0].legend()\nax[1].legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-10T14:51:24.147055Z","iopub.execute_input":"2023-04-10T14:51:24.147357Z","iopub.status.idle":"2023-04-10T14:51:24.528724Z","shell.execute_reply.started":"2023-04-10T14:51:24.147327Z","shell.execute_reply":"2023-04-10T14:51:24.527698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save Model","metadata":{}},{"cell_type":"code","source":"model.load_weights('ckpt')\nmodel.save('models',save_format='tf')","metadata":{"execution":{"iopub.status.busy":"2023-04-10T14:51:24.530333Z","iopub.execute_input":"2023-04-10T14:51:24.531391Z","iopub.status.idle":"2023-04-10T14:51:49.552477Z","shell.execute_reply.started":"2023-04-10T14:51:24.531353Z","shell.execute_reply":"2023-04-10T14:51:49.5514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for idx,i in enumerate(model.layers):\n    print('Encoder layers:' if idx==0 else 'Decoder layers: ')\n    for j in i.layers:\n        print(j)\n    print('---------------------')","metadata":{"execution":{"iopub.status.busy":"2023-04-10T14:51:49.557229Z","iopub.execute_input":"2023-04-10T14:51:49.557535Z","iopub.status.idle":"2023-04-10T14:51:49.566934Z","shell.execute_reply.started":"2023-04-10T14:51:49.557505Z","shell.execute_reply":"2023-04-10T14:51:49.565907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Inference Model","metadata":{}},{"cell_type":"code","source":"class ChatBot(tf.keras.models.Model):\n    def __init__(self,base_encoder,base_decoder,*args,**kwargs):\n        super().__init__(*args,**kwargs)\n        self.encoder,self.decoder=self.build_inference_model(base_encoder,base_decoder)\n\n    def build_inference_model(self,base_encoder,base_decoder):\n        encoder_inputs=tf.keras.Input(shape=(None,))\n        x=base_encoder.layers[0](encoder_inputs)\n        x=base_encoder.layers[1](x)\n        x,encoder_state_h,encoder_state_c=base_encoder.layers[2](x)\n        encoder=tf.keras.models.Model(inputs=encoder_inputs,outputs=[encoder_state_h,encoder_state_c],name='chatbot_encoder')\n\n        decoder_input_state_h=tf.keras.Input(shape=(lstm_cells,))\n        decoder_input_state_c=tf.keras.Input(shape=(lstm_cells,))\n        decoder_inputs=tf.keras.Input(shape=(None,))\n        x=base_decoder.layers[0](decoder_inputs)\n        x=base_encoder.layers[1](x)\n        x,decoder_state_h,decoder_state_c=base_decoder.layers[2](x,initial_state=[decoder_input_state_h,decoder_input_state_c])\n        decoder_outputs=base_decoder.layers[-1](x)\n        decoder=tf.keras.models.Model(\n            inputs=[decoder_inputs,[decoder_input_state_h,decoder_input_state_c]],\n            outputs=[decoder_outputs,[decoder_state_h,decoder_state_c]],name='chatbot_decoder'\n        )\n        return encoder,decoder\n\n    def summary(self):\n        self.encoder.summary()\n        self.decoder.summary()\n\n    def softmax(self,z):\n        return np.exp(z)/sum(np.exp(z))\n\n    def sample(self,conditional_probability,temperature=0.5):\n        conditional_probability = np.asarray(conditional_probability).astype(\"float64\")\n        conditional_probability = np.log(conditional_probability) / temperature\n        reweighted_conditional_probability = self.softmax(conditional_probability)\n        probas = np.random.multinomial(1, reweighted_conditional_probability, 1)\n        return np.argmax(probas)\n\n    def preprocess(self,text):\n        text=clean_text(text)\n        seq=np.zeros((1,max_sequence_length),dtype=np.int32)\n        for i,word in enumerate(text.split()):\n            seq[:,i]=sequences2ids(word).numpy()[0]\n        return seq\n    \n    def postprocess(self,text):\n        text=re.sub(' - ','-',text.lower())\n        text=re.sub(' [.] ','. ',text)\n        text=re.sub(' [1] ','1',text)\n        text=re.sub(' [2] ','2',text)\n        text=re.sub(' [3] ','3',text)\n        text=re.sub(' [4] ','4',text)\n        text=re.sub(' [5] ','5',text)\n        text=re.sub(' [6] ','6',text)\n        text=re.sub(' [7] ','7',text)\n        text=re.sub(' [8] ','8',text)\n        text=re.sub(' [9] ','9',text)\n        text=re.sub(' [0] ','0',text)\n        text=re.sub(' [,] ',', ',text)\n        text=re.sub(' [?] ','? ',text)\n        text=re.sub(' [!] ','! ',text)\n        text=re.sub(' [$] ','$ ',text)\n        text=re.sub(' [&] ','& ',text)\n        text=re.sub(' [/] ','/ ',text)\n        text=re.sub(' [:] ',': ',text)\n        text=re.sub(' [;] ','; ',text)\n        text=re.sub(' [*] ','* ',text)\n        text=re.sub(' [\\'] ','\\'',text)\n        text=re.sub(' [\\\"] ','\\\"',text)\n        return text\n\n    def call(self,text,config=None):\n        input_seq=self.preprocess(text)\n        states=self.encoder(input_seq,training=False)\n        target_seq=np.zeros((1,1))\n        target_seq[:,:]=sequences2ids(['<start>']).numpy()[0][0]\n        stop_condition=False\n        decoded=[]\n        while not stop_condition:\n            decoder_outputs,new_states=self.decoder([target_seq,states],training=False)\n#             index=tf.argmax(decoder_outputs[:,-1,:],axis=-1).numpy().item()\n            index=self.sample(decoder_outputs[0,0,:]).item()\n            word=ids2sequences([index])\n            if word=='<end> ' or len(decoded)>=max_sequence_length:\n                stop_condition=True\n            else:\n                decoded.append(index)\n                target_seq=np.zeros((1,1))\n                target_seq[:,:]=index\n                states=new_states\n        return self.postprocess(ids2sequences(decoded))\n\nchatbot=ChatBot(model.encoder,model.decoder,name='chatbot')\nchatbot.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-10T14:51:49.568594Z","iopub.execute_input":"2023-04-10T14:51:49.568975Z","iopub.status.idle":"2023-04-10T14:51:51.437606Z","shell.execute_reply.started":"2023-04-10T14:51:49.56893Z","shell.execute_reply":"2023-04-10T14:51:51.436789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(chatbot.encoder,to_file='encoder.png',show_shapes=True,show_layer_activations=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T14:51:51.438651Z","iopub.execute_input":"2023-04-10T14:51:51.439025Z","iopub.status.idle":"2023-04-10T14:51:51.715029Z","shell.execute_reply.started":"2023-04-10T14:51:51.438986Z","shell.execute_reply":"2023-04-10T14:51:51.713749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(chatbot.decoder,to_file='decoder.png',show_shapes=True,show_layer_activations=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T14:51:51.717369Z","iopub.execute_input":"2023-04-10T14:51:51.717837Z","iopub.status.idle":"2023-04-10T14:51:52.005032Z","shell.execute_reply.started":"2023-04-10T14:51:51.717784Z","shell.execute_reply":"2023-04-10T14:51:52.003825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Time to Chat","metadata":{}},{"cell_type":"code","source":"def print_conversation(texts):\n    for text in texts:\n        print(f'You: {text}')\n        print(f'Bot: {chatbot(text)}')\n        print('========================')","metadata":{"execution":{"iopub.status.busy":"2023-04-10T14:51:52.007232Z","iopub.execute_input":"2023-04-10T14:51:52.008188Z","iopub.status.idle":"2023-04-10T14:51:52.01474Z","shell.execute_reply.started":"2023-04-10T14:51:52.008136Z","shell.execute_reply":"2023-04-10T14:51:52.013803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print_conversation([\n    'hi',\n    'do yo know me?',\n    'what is your name?',\n    'you are bot?',\n    'hi, how are you doing?',\n    \"i'm pretty good. thanks for asking.\",\n    \"Don't ever be in a hurry\",\n    '''I'm gonna put some dirt in your eye ''',\n    '''You're trash ''',\n    '''I've read all your research on nano-technology ''',\n    '''You want forgiveness? Get religion''',\n    '''While you're using the bathroom, i'll order some food.''',\n    '''Wow! that's terrible.''',\n    '''We'll be here forever.''',\n    '''I need something that's reliable.''',\n    '''A speeding car ran a red light, killing the girl.''',\n    '''Tomorrow we'll have rice and fish for lunch.''',\n    '''I like this restaurant because they give you free bread.'''\n])","metadata":{"execution":{"iopub.status.busy":"2023-04-10T14:54:09.856276Z","iopub.execute_input":"2023-04-10T14:54:09.85697Z","iopub.status.idle":"2023-04-10T14:54:16.78249Z","shell.execute_reply.started":"2023-04-10T14:54:09.856925Z","shell.execute_reply":"2023-04-10T14:54:16.781008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}